# 🧠 Machine Learning Specialization by Stanford Online and DeepLearning.ai

This repository contains detailed notes, code, and projects from the **Machine Learning Specialization** taught by **Andrew Ng**, offered via **DeepLearning.AI** on Coursera. The specialization dives into the foundational and advanced concepts of modern machine learning, with hands-on implementation using **Python** and **TensorFlow**.

---

## 🚀 Specialization Overview

The specialization is structured into 3 courses:

1. **Supervised Machine Learning: Regression and Classification**
2. **Advanced Learning Algorithms**
3. **Unsupervised Learning, Recommenders, Reinforcement Learning**

Each course builds up practical skills, from classical ML to deep learning and reinforcement learning.

---

## 📚 Topics Covered

### 🔹 1. Supervised Learning

- **Linear Regression** and **Logistic Regression**
- **Cost functions**, **Gradient Descent**, and **Feature Scaling**
- **Regularization** (L1/L2), **Overfitting**, and **Bias-Variance Trade-off**
- **Multiclass Classification** using One-vs-All

### 🔹 2. Neural Networks & Deep Learning

- **Forward Propagation** and **Backpropagation**
- **Activation Functions**: ReLU, Sigmoid, Tanh
- **Weight Initialization**
- **Gradient Checking**
- **Dropout Regularization**
- **Batch Normalization**
- Implemented using **NumPy** and then in **TensorFlow**

### 🔹 3. Optimization Techniques

- **Stochastic Gradient Descent (SGD)**
- **Mini-Batch Gradient Descent**
- **Momentum Optimization**
- **RMSProp**
- **Adam Optimizer** – Combines Momentum and RMSProp, widely used in deep learning

### 🔹 4. TensorFlow Framework

- Low-level and high-level APIs of **TensorFlow 2.x**
- **Keras** for model definition and training
- Model building using `Sequential` and `Functional` APIs
- Custom training loops using `tf.GradientTape`
- **Callbacks**, model checkpoints, and learning rate schedulers

### 🔹 5. Unsupervised Learning

- **k-Means Clustering**
- **Dimensionality Reduction**: PCA
- **Anomaly Detection**
- **Gaussian Mixture Models**
- **t-SNE** for visualization

### 🔹 6. Recommender Systems

- **Collaborative Filtering** using Matrix Factorization
- **Content-Based Filtering**
- **Hybrid Systems**
- **Gradient descent-based learning of user/item embeddings**

### 🔹 7. Reinforcement Learning (RL)

> Though not part of the classical ML course, it's introduced in the specialization finale.

- **Markov Decision Processes (MDPs)**
- **Q-Learning** – Value-based RL method
- **Deep Q-Networks (DQN)** – Combining Q-Learning with neural networks
- **Experience Replay** and **Target Networks**
- Use of **ε-greedy policies**
- Discussion of **Bellman Equations**
- High-level concepts behind **Policy Gradient** methods

---

## 📁 Repository Structure

```bash
.
├── Course1_Supervised_Learning/
├── Course2_Advanced_Learning/
├── Course3_Unsupervised_RL_Recommenders/
├── Projects/
├── README.md
└── requirements.txt
